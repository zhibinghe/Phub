## scenario #1
library(foreach)
#### Main function
phub = function(G,A,rho,lam,pen.type=c("plog","plasso","log"),iter.max=1000,tol=1e-4){
  ## f(G(t)|Z(t)=k,A)
  pen.type = match.arg(pen.type)
  posterior = function(G,A,rho){
    T = dim(G)[1]; n = dim(G)[2]; q = dim(A)[1]
    H = Pr_cond = matrix(NA,T,q)
    for(t in 1:T) Pr_cond[t,] = apply(t(t(A)^G[t,])*t(t(1-A)^(1-G[t,])),1,prod)
    ## posterior probability H and loglikelihood
    Pr_G = t(t(Pr_cond)*rho)
    # condtional probability is extremely small for some t
    # thus devide the sample into 2 parts: computable and numerical underflow
    id = which(rowSums(Pr_G)==0)   # unnormal sample index
    Pr_G1 = Pr_G[setdiff(1:T,id),] # normal group
    H[setdiff(1:T,id),] = Pr_G1/rowSums(Pr_G1)
    l1 = sum(log(rowSums(Pr_G1))); l2 = 0
    btm = matrix(NA,length(id),q)
    if(length(id)!=0){
      for(ii in 1:length(id)){
        pid = which(G[ii,]==1)
        if(length(pid)!=0) t1 = apply(A,1,function(x)sum(x[pid]))
        else t1 = rep(0,q)
        t2 = rowSums(log(1-A)[,setdiff(1:n,pid)])
        btm[ii,] = t1+t2+log(rho)
      }
      ct = apply(btm,1,max)
      l2 = sum(ct+log(rowSums(exp(btm-ct))))
      H[id,] = t(apply(exp(btm-ct),1,function(x) x/sum(x)))
    }
    return(list(H=H,l=l1+l2))
  }
  ## update rho: some rho will shrink to 0
  if(pen.type=="log"){
    hatrho = function(rho,H){
      Mi = sum(rho!=0)
      if(Mi*lam==1) stop("\nPlease input a new lam avoiding 1-M*lam is 0\n",call.=FALSE)
      pars = sapply((colMeans(H) - lam)/(1-Mi*lam),function(x) max(0,x))
      pars[pars<tol] = 0
      return(pars)
    } 
  } 
  else{
    hatrho = function(rho,H){
      T = dim(G)[1]
      Hx = colSums(H)
      ind = which(rho!=0); len = length(ind)
      eqft = function(t) sum(t)
      if(pen.type=="plasso"){
        # convex function
        ft = function(t) -sum(Hx[ind]*log(t)) + T*lam*(1-t[1])
        pars = Rsolnp::solnp(pars=rho[ind],fun=ft,eqfun=eqft,eqB=1,LB=rep(0,len),
                             UB=rep(1,len),control=list(trace=0))$pars
      }
      else{
        epsi = 1e-8
        ans = list()
        ft = function(t) -sum(Hx[ind]*log(t)) + T*lam*sum(log(epsi+t[-1]))
        fun = function(i){
          if(i==1) par = rho[ind]
          else {par = runif(len); par = par/sum(par)} # normalized
          sol = Rsolnp::solnp(pars=par,fun=ft,eqfun=eqft,eqB=1,LB=rep(0,len),
                              UB=rep(1,len),control=list(trace=0))
          ans$pars = sol$pars
          ans$values = tail(sol$values,1)
          return(ans)
        }
        # adding one initial values rho from the last step.
        fval = lapply(as.list(1:3),fun) # repeatation
        best = sapply(fval,function(x) x$values)
        pars = fval[[which.min(best)]]$pars
      }
      pars[pars<tol] = 0
      pars[1] = 1 - sum(pars[-1]) # sum is 1
      rho[ind] = pars
      return(rho)
    }
  }
  ## update A: Am. will be 0 if rho_m=0
  hatA = function(G,H){
    q = dim(H)[2]; n = dim(G)[2]
    HatA = matrix(NA,q,n)
    for(m in 1:q){
      if (all(H[,m]==0)) HatA[m,] = 0
      else HatA[m,] = colSums(H[,m]*G)/sum(H[,m])
    }
    diag(HatA[-1,]) = 1 # Amm must be 1
    return(HatA)
  }
  ## EM Iteration
  count = 0;diff = 1
  L = vector();L[1] = 1
  while(count < iter.max & diff > 1e-6){
    count = count + 1
    # E Step
    post = posterior(G,A,rho)
    H = post$H
    L[count+1] = post$l
    #cat("count and likelihood:",c(count,tail(L,1)),sep="\n")
    if(is.infinite(L[count+1])) break
    if(is.na(tail(L,1))) break
    # M Step
    rho = hatrho(rho,H)
    A = hatA(G,H)
    diff = abs((L[count+1]-L[count])/L[count+1])
  }
  return(list(A=A,rho=rho,l=L[count+1],iter=count))
}
##########################################################
####
GenA = function(n,n0,pi,alpha=1){
  A = matrix(NA,n0,n)
  A_lab = vector("list",n0)
  # set of followers except hub itself
  for(i in 1:n0) A_lab[[i]] = seq(n0+i,n,n0)
  for(i in 1:n0){
    A[i,A_lab[[i]]] = runif(length(A_lab[[i]]),0.2,0.4)*alpha
    A[i,-A_lab[[i]]] = runif(n-length(A_lab[[i]]),0,0.2)*alpha
  }
  diag(A) = 1
  return(rbind(pi*alpha,A))
}
#
GenG = function(A,T,rho){
  n0=dim(A)[1]; n=dim(A)[2]
  G = matrix(0,T,n)
  hub = rep(NA,T)
  for(t in 1:T){
    hub[t] = sample(1:n0,1,prob=rho)
    G[t,]=rbinom(n,1,prob=A[hub[t],])
  }
  return(G)
}
####
n0 = 10; n=500; T=1000
M = 300 
Iter = 3
lam = seq(0.008,0.015,0.001)
## scenario 1: lam = 0.010-0.020
## scenario 2: lam = 0.008-0.018
##
# Bic selection with optimal lambda
bic.sele = function(lam){
  model = lapply(lam,phub,G=G0,A=A,rho=rho,pen.type="plog")
  sel = matrix(NA,length(lam),(M+1))
  bbic = baic = rep(NA,length(lam))
  bic = function(x,hatM) x-0.5*log(T)*(n+1)*hatM # BIC criteria
  aic = function(x,hatM) x-(n+1)*hatM # AIC criteria
  for(i in 1:length(lam)){
    sel[i,] = model[[i]]$rho
    tc = sum(model[[i]]$rho!=0)
    bbic[i] = bic(model[[i]]$l,tc)
    baic[i] = aic(model[[i]]$l,tc)
  }
  out = cbind(lam,bbic,baic,sel)
  colnames(out) = c("lambda","bic","aic",paste("rho",0:M,sep=""))
  return(out)
} 
# parallel computing
c = 4 # number of cpu cores
cl = parallel::makeCluster(c)
doParallel::registerDoParallel(cl)
out = foreach::foreach(iterators::icount(Iter),.errorhandling="pass") %dopar% {
  rho0 = c(0.2,runif(n0,min=0.8/(2*n0),max=0.8*2/n0))
  rho0 = rho0/sum(rho0)
  pi0 = rep(0.05,n)
  A0 = GenA(n,n0,pi0,alpha=0.7)
  G0 = GenG(A0,T,rho0)
  # initial A
  A = matrix(NA,M,n)
  for(i in 1:M)A[i,] = colSums(G0[,i]*G0)/sum(G0[,i])
  diag(A) = 1; A = rbind(runif(n),A)
  # initial rho
  rho = c(0.2,rep(0.8/M,M))
  bic.sele(lam)
}
parallel::stopCluster(cl)

##
save.image(paste("phub_","n",n0,"_","M",M,"_","N",n,"_","T",T,"_","r05","_",".RData",sep=""))








