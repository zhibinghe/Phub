#' EM nested with lasso algorithm for hub model component selection
#'
#' @param G  observed group data, a T*n matrix
#' @param A  a matrix containg correlation among nodes; first row is the nonleader case
#' @param rho a vector composed of component weight; prior probability of components.
#' @param lam tuning parameter for component selection, lambda*Df; if lam=0, becomes a normal EM without penalty
#' @param iter maximum iteration steps
#' @param tol tolerated chnage for log-likelihood

#' @return a list of components
#' \item{A}{a matrix containg estimated correlation among nodes}
#' \item{rho}{a vector containing estimated component weight}
#' \item{l}{log-likelihood}
#' \item{iteration}{number of iterations used to converge}
#' @export
#'
#' @examples
#' n0 = 5; n=100
#' A0 = GenA(n,n0,0.4,0.1,rep(0.05,n))
#' G0 = GenG(A0,1000,c(0.2,rep(0.8/n0,n0)))
#' M = 10
#' A = matrix(runif((M+1)*n),nrow=(M+1)); diag(A[-1,])=1
#' rho = runif(M+1); rho = rho/sum(rho)
#' EM.opt(G0,A,rho,0.040)$rho
#' EM.hub(G0,A,rho,0.045,nohub=TRUE)$rho
#' EMM.opt(G0,M,0.040)$rho
#' EMM.hub(G0,M,0.045)$rho
library(Phub)
library(Rsolnp)
EM.opt = function(G,A,rho,lam,iter=1000,tol=10^(-4)){
  ## f(G(t)|Z(t)=k,A)
  cond.f = function(G,A){
    T = dim(G)[1]; M = dim(A)[1]
    Pr_cond = matrix(NA,T,M)
    for(t in 1:T) Pr_cond[t,] = apply(t(t(A)^G[t,])*t(t(1-A)^(1-G[t,])),1,prod)
    return(Pr_cond)
  }
  ## posterior prob. Htm and loglikelihood
  posterior = function(rho,Pr_cond){
    T = dim(Pr_cond)[1]; q = dim(Pr_cond)[2]
    H = matrix(NA,T,q)
    Htm = t(t(Pr_cond)*rho)
    H = Htm/rowSums(Htm)
    loglik = sum(log(rowSums(Htm)))
    return(list(H=H,l=loglik))
  }
  ## update rho: some rho may shrink to 0
  hatrho = function(x,Hx){
    ##### need to rewrite
    # Hx: colSums of H
    epsi = 10^(-6)
    T = dim(G)[1]
    ind = which(x!=0)
    ft = function(t) -sum(Hx[ind]*log(t)) + T*lam*sum(log(epsi+t[-1]))
    eqft = function(t) sum(t)
    len = length(ind)
    pars = gosolnp(fun=ft,eqfun=eqft,eqB=1,LB=rep(0,len),UB=rep(1,len),control=list(trace=0),n.restarts=5)$pars
    pars[pars<tol] = 0
    x[ind] = pars
    return(x)
  }
  ## update A: Am. will be 0 if rho_m=0
  hatA = function(G,H){
    q = dim(H)[2]; n = dim(G)[2]
    HatA = matrix(NA,q,n)
    for(m in 1:q){
      if (all(H[,m]==0)) HatA[m,] = 0
      else HatA[m,] = colSums(H[,m]*G)/sum(H[,m])
    }
    diag(HatA[-1,]) = 1 # No need to estimate A(m+1)m
    return(HatA)
  }
  ## EM Iteration
  count = 0;diff = 1
  L = vector();L[1] = 1
  while(count < iter & diff > 0.01){
    count = count + 1
    # E Step
    post = posterior(rho,cond.f(G,A))
    H = post$H
    L[count+1] = post$l
    if(is.infinite(L[count+1])) break
    # M Step
    rho = hatrho(rho,colSums(H))
    A = hatA(G,H)
    diff = abs(L[count+1]-L[count])
  }
  return(list(A=A,rho=rho,l=L[count+1],iteration=count))
}
## Multiple Initial points
EMM.opt = function(G,M,lam,rep=5,nohub=TRUE,iter=1000,tol=10^(-4)){
  T = dim(G)[1]; n = dim(G)[2]
  # repeatation
  outp = list(rep); cur = rep(NA,rep)
  for(r in 1:rep){
    rho = runif(M+1); rho = rho/sum(rho)
    A = matrix(runif((M+1)*n),nrow=(M+1))
    diag(A[-1,])=1
    outp[[r]] = EM.opt(G,A,rho,lam)
    cur[r] = outp[[r]]$l
  }
  maxid = which.max(cur)
  return(outp[[maxid]])
}

